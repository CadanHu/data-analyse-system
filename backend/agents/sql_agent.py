"""
SQL Agent æ ¸å¿ƒæ¨¡å—
"""
import json
import re
import httpx
from typing import Dict, Any, Optional, List, AsyncGenerator
from config import API_KEY, API_BASE_URL, CHAT_MODEL, REASONER_MODEL, MAX_RETRY_COUNT
from utils.prompt_templates import (
    SQL_GENERATION_PROMPT, SUMMARY_PROMPT, CHART_CONFIG_PROMPT, 
    INTENT_CLASSIFICATION_PROMPT, CHAT_RESPONSE_PROMPT, PLAN_GENERATION_PROMPT
)
from services.schema_service import SchemaService
from services.sql_executor import SQLExecutor


class SQLAgent:
    async def _chat_completion(self, messages: List[Dict[str, str]], temperature: float = 0.7) -> str:
        async with httpx.AsyncClient(timeout=60.0) as client:
            response = await client.post(
                f"{API_BASE_URL}/chat/completions",
                headers={
                    "Authorization": f"Bearer {API_KEY}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": CHAT_MODEL,
                    "messages": messages,
                    "temperature": temperature
                }
            )
            response.raise_for_status()
            result = response.json()
            
            # --- æ ¸å¿ƒæ”¹è¿›ï¼šæ‰“å°è¯¦ç»†äº¤äº’æ—¥å¿— ---
            print(f"\nğŸ“¡ [DeepSeek äº¤äº’è¯¦æƒ…]")
            print(f"ğŸ“¥ [æ¨¡å‹]: {result.get('model')}")
            raw_content = result.get('choices')[0].get('message').get('content')
            print(f"ğŸ“¥ [åŸå§‹å“åº”]: {json.dumps(raw_content, ensure_ascii=False, indent=2)}")
            usage = result.get("usage", {})
            print(f"ğŸ’° [Token æ¶ˆè€—]: æ€»è®¡ {usage.get('total_tokens', 0)}, æç¤º {usage.get('prompt_tokens', 0)}, å›ç­” {usage.get('completion_tokens', 0)}")
            print("-" * 30)
            
            return result["choices"][0]["message"]["content"]
    
    async def _chat_completion_stream(
        self, 
        messages: List[Dict[str, str]], 
        temperature: float = 0.7,
        enable_thinking: bool = True
    ) -> AsyncGenerator[Dict[str, Any], None]:
        # æ ¹æ®å¼€å…³é€‰æ‹©æ¨¡å‹
        active_model = REASONER_MODEL if enable_thinking else CHAT_MODEL
        
        request_body = {
            "model": active_model,
            "messages": messages,
            "temperature": temperature,
            "stream": True,
            "stream_options": {"include_usage": True} # å¯ç”¨ç²¾å‡†ç»“ç®—
        }
        
        print(f"\nğŸ“¡ [DeepSeek æµå¼è¯·æ±‚å‘èµ·]")
        print(f"ğŸ“¤ [æ¨¡å‹]: {active_model} | [æ€è€ƒæ¨¡å¼]: {enable_thinking}")
        
        full_content = ""
        full_reasoning = ""

        async with httpx.AsyncClient(timeout=120.0) as client:
            async with client.stream(
                "POST",
                f"{API_BASE_URL}/chat/completions",
                headers={
                    "Authorization": f"Bearer {API_KEY}",
                    "Content-Type": "application/json"
                },
                json=request_body
            ) as response:
                if response.status_code != 200:
                    error_text = await response.aread()
                    print(f"âŒ DeepSeek API é”™è¯¯: {response.status_code} - {error_text.decode()}")
                response.raise_for_status()
                
                async for line in response.aiter_lines():
                    if line.startswith("data: "):
                        data_str = line[6:]
                        if data_str == "[DONE]":
                            break
                        try:
                            chunk = json.loads(data_str)
                            
                            # 1. ç²¾ç¡®ç»“ç®—æ—¥å¿— (é€šå¸¸åœ¨æœ€åä¸€ä¸ª chunk)
                            if chunk.get("usage"):
                                usage = chunk["usage"]
                                print(f"\nğŸ’° [æµå¼ Token ç»“ç®—]")
                                print(f"   - æ€»è®¡: {usage.get('total_tokens', 0)}")
                                print(f"   - æç¤º (Prompt): {usage.get('prompt_tokens', 0)}")
                                print(f"   - å›ç­” (Completion): {usage.get('completion_tokens', 0)}")
                                if usage.get('completion_tokens_details', {}).get('reasoning_tokens'):
                                    print(f"   - æ¨ç† (Reasoning): {usage['completion_tokens_details']['reasoning_tokens']}")
                            
                            # 2. å†…å®¹å¤„ç†ä¸å®æ—¶æç¤º
                            if chunk.get("choices"):
                                delta = chunk["choices"][0].get("delta", {})
                                
                                # å®æ—¶æ•è·æ€è€ƒ
                                reasoning = delta.get("reasoning_content", "")
                                if reasoning:
                                    if not full_reasoning:
                                        print("ğŸ§  [AI æ­£åœ¨æ€è€ƒ...]")
                                    full_reasoning += reasoning
                                
                                # å®æ—¶æ•è·å›ç­”
                                content = delta.get("content", "")
                                if content:
                                    full_content += content
                                
                                if reasoning or content:
                                    yield {
                                        "reasoning_content": reasoning,
                                        "content": content
                                    }
                        except json.JSONDecodeError:
                            pass
                
                # è¯·æ±‚ç»“æŸæ—¶ï¼Œæ‰“å°å®Œæ•´å“åº”å†…å®¹
                if full_content:
                    print(f"\nğŸ“¥ [AI å®Œæ•´å›ç­”]:\n{full_content}")
                if full_reasoning:
                    print(f"\nğŸ§  [AI å®Œæ•´æ€è€ƒè¿‡ç¨‹]:\n{full_reasoning}")
                print("-" * 30)
    async def _classify_intent(self, question: str) -> str:
        prompt = INTENT_CLASSIFICATION_PROMPT.format(question=question)
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œè´Ÿè´£æ ¹æ®ç”¨æˆ·é—®é¢˜åˆ¤æ–­å…¶æ„å›¾ã€‚"},
            {"role": "user", "content": prompt}
        ]
        response_content = await self._chat_completion(messages, temperature=0.0)
        try:
            intent_json = json.loads(response_content)
            return intent_json.get("intent", "chat")
        except json.JSONDecodeError:
            return "chat"
                                                                
    async def generate_sql_stream(
        self,
        question: str,
        schema: str,
        history: str = "",
        enable_thinking: bool = False,
        database_name: str = "ä¸šåŠ¡æ•°æ®åº“",
        database_type_info: str = "",
        database_version: str = "unknown",
        table_list_query: str = "è¯·ä½¿ç”¨ï¼šSHOW TABLES",
        quote_char: str = '"'
    ) -> AsyncGenerator[Dict[str, Any], None]:
        prompt = SQL_GENERATION_PROMPT.format(
            database_name=database_name,
            database_type_info=database_type_info,
            database_version=database_version,
            schema=schema,
            history=history,
            question=question,
            table_list_query=table_list_query,
            quote_char=quote_char
        )

        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®åˆ†æåŠ©æ‰‹ã€‚"},
            {"role": "user", "content": prompt}
        ]

        full_content = ""
        async for delta in self._chat_completion_stream(messages, temperature=0.1, enable_thinking=enable_thinking):
            if delta["reasoning_content"]:
                yield {"type": "reasoning", "content": delta["reasoning_content"]}
            if delta["content"]:
                full_content += delta["content"]
                yield {"type": "content", "content": delta["content"]}
        
        yield {"type": "done", "result": self._parse_json_response(full_content)}

    async def _generate_chat_response_stream(
        self,
        question: str,
        history: str = "",
        enable_thinking: bool = False,
        database_name: str = "æœªçŸ¥",
        database_type: str = "æœªçŸ¥",
        tables: str = "æœªçŸ¥"
    ) -> AsyncGenerator[Dict[str, Any], None]:
        prompt = CHAT_RESPONSE_PROMPT.format(
            history=history,
            question=question,
            database_name=database_name,
            database_type=database_type,
            tables=tables
        )

        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½æ•°æ®åˆ†æåŠ©æ‰‹ã€‚"},
            {"role": "user", "content": prompt}
        ]

        full_content = ""
        async for delta in self._chat_completion_stream(messages, temperature=0.7, enable_thinking=enable_thinking):
            if delta["reasoning_content"]:
                yield {"type": "reasoning", "content": delta["reasoning_content"]}
            if delta["content"]:
                full_content += delta["content"]
                yield {"type": "content", "content": delta["content"]}
        
        yield {"type": "done", "result": full_content or ""}
        
    def _parse_json_response(self, content: str) -> Dict[str, Any]:
        try:
            json_match = re.search(r'\{[\s\S]*\}', content)
            if json_match:
                json_str = json_match.group(0)
                return json.loads(json_str)
            return json.loads(content)
        except Exception:
            return {
                "sql": "",
                "chart_type": "table",
                "viz_config": {},
                "reasoning": "è§£æå¤±è´¥"
            }

    async def generate_summary_stream(
        self,
        sql_result: str,
        chart_type: str,
        enable_thinking: bool = False
    ) -> AsyncGenerator[Dict[str, Any], None]:
        prompt = SUMMARY_PROMPT.format(
            sql_result=sql_result,
            chart_type=chart_type
        )

        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®åˆ†æå¸ˆã€‚"},
            {"role": "user", "content": prompt}
        ]

        full_content = ""
        async for delta in self._chat_completion_stream(messages, temperature=0.3, enable_thinking=enable_thinking):
            if delta["reasoning_content"]:
                yield {"type": "reasoning", "content": delta["reasoning_content"]}
            if delta["content"]:
                full_content += delta["content"]
                yield {"type": "content", "content": delta["content"]}
        
        yield {"type": "done", "result": full_content or ""}

    async def generate_chart_config(
        self,
        sql_result: Dict[str, Any],
        chart_type: str,
        viz_config: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        æ ¹æ® SQL ç»“æœå’Œ AI å»ºè®®ç”Ÿæˆå›¾è¡¨é…ç½®
        """
        try:
            columns = sql_result.get("columns", [])
            rows = sql_result.get("rows", [])
            viz_config = viz_config or {}
            
            # ç‰¹æ®Šå¤„ç†ï¼šå•è¡Œå•åˆ— -> card
            if chart_type == "card" or (len(rows) == 1 and len(columns) == 1):
                val = rows[0][columns[0]]
                return {
                    "chart_type": "card",
                    "value": val,
                    "label": viz_config.get("title") or columns[0],
                    "unit": ""
                }

            if chart_type == "table":
                return {"chart_type": "table"}

            if not rows or not columns:
                return self._get_default_chart_config(chart_type)

            # å¯¹äºå¤æ‚å›¾è¡¨ï¼Œè°ƒç”¨ AI ç”Ÿæˆé…ç½®
            complex_types = [
                "area", "scatter", "radar", "funnel", "gauge", "heatmap", 
                "treemap", "sankey", "boxplot", "waterfall", "candlestick"
            ]
            if chart_type in complex_types:
                ai_config = await self._generate_complex_chart_config(sql_result, chart_type)
                if ai_config:
                    return ai_config

            # æ™ºèƒ½æ˜ å°„ X/Y è½´ (åŸºç¡€å›¾è¡¨å›é€€æ–¹æ¡ˆ)
            x_axis = viz_config.get("x") if viz_config.get("x") in columns else None
            y_axis = viz_config.get("y") if viz_config.get("y") in columns else None

            if not x_axis or not y_axis:
                # é™çº§ï¼šå¯å‘å¼åŒ¹é…
                numeric_cols = [c for c in columns if isinstance(rows[0].get(c), (int, float))]
                category_cols = [c for c in columns if c not in numeric_cols]
                
                x_axis = x_axis or (category_cols[0] if category_cols else columns[0])
                y_axis = y_axis or (numeric_cols[0] if numeric_cols else (columns[1] if len(columns) > 1 else columns[0]))

            title = viz_config.get("title") or "åˆ†æç»“æœ"

            if chart_type == "bar":
                return {
                    "title": {"text": title, "left": "center", "top": 10},
                    "tooltip": {"trigger": "axis"},
                    "grid": {"top": 60, "bottom": 40, "left": 60, "right": 20},
                    "xAxis": {"type": "category", "data": [str(row[x_axis]) for row in rows], "axisLabel": {"rotate": 30 if len(rows) > 5 else 0}},
                    "yAxis": {"type": "value"},
                    "series": [{"name": y_axis, "type": "bar", "data": [row[y_axis] for row in rows], "itemStyle": {"borderRadius": [4, 4, 0, 0]}}]
                }
            elif chart_type == "line" or chart_type == "area":
                series_config = {
                    "name": y_axis, 
                    "type": "line", 
                    "data": [row[y_axis] for row in rows], 
                    "smooth": True, 
                    "symbol": "circle", 
                    "symbolSize": 8
                }
                if chart_type == "area":
                    series_config["areaStyle"] = {"opacity": 0.3}
                
                return {
                    "title": {"text": title, "left": "center", "top": 10},
                    "tooltip": {"trigger": "axis"},
                    "grid": {"top": 60, "bottom": 40, "left": 60, "right": 20},
                    "xAxis": {"type": "category", "data": [str(row[x_axis]) for row in rows]},
                    "yAxis": {"type": "value"},
                    "series": [series_config]
                }
            elif chart_type == "pie":
                return {
                    "title": {"text": title, "left": "center", "top": 10},
                    "tooltip": {"trigger": "item"},
                    "series": [{
                        "name": y_axis,
                        "type": "pie",
                        "radius": ["40%", "70%"],
                        "avoidLabelOverlap": True,
                        "itemStyle": {"borderRadius": 10, "borderColor": "#fff", "borderWidth": 2},
                        "data": [{"value": row[y_axis], "name": str(row[x_axis])} for row in rows]
                    }]
                }
            
            return self._get_default_chart_config(chart_type)
        except Exception as e:
            print(f"âŒ å›¾è¡¨ç”Ÿæˆé”™è¯¯: {str(e)}")
            return self._get_default_chart_config(chart_type)

    async def _generate_complex_chart_config(self, sql_result: Dict[str, Any], chart_type: str) -> Optional[Dict[str, Any]]:
        """è°ƒç”¨ AI ç”Ÿæˆå¤æ‚å›¾è¡¨çš„ ECharts é…ç½®"""
        from utils.json_utils import json_dumps
        try:
            prompt = CHART_CONFIG_PROMPT.format(
                sql_result=json_dumps(sql_result, indent=2),
                chart_type=chart_type
            )
            messages = [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®å¯è§†åŒ–ä¸“å®¶ï¼Œæ“…é•¿ä½¿ç”¨ EChartsã€‚"},
                {"role": "user", "content": prompt}
            ]
            
            response = await self._chat_completion(messages, temperature=0.2)
            
            # æå– JSON
            json_match = re.search(r'\{[\s\S]*\}', response)
            if json_match:
                config = json.loads(json_match.group(0))
                return config
            return None
        except Exception as e:
            print(f"âŒ AI å¤æ‚å›¾è¡¨ç”Ÿæˆå¤±è´¥: {str(e)}")
            return None

    def _get_default_chart_config(self, chart_type: str) -> Dict[str, Any]:
        return {
            "title": {"text": "æš‚æ— æœ‰æ•ˆæ•°æ®", "left": "center"},
            "series": []
        }

    async def process_question_with_history(
        self,
        question: str,
        history_str: str,
        enable_thinking: bool = False
    ) -> AsyncGenerator[Dict[str, Any], None]:
        """å¢å¼ºçš„å¤„ç†é€»è¾‘ï¼šåŒ…å« viz_config è§£æ"""
        from config import DATABASES
        
        schema = await SchemaService.get_full_schema(include_sample=True)
        tables = await SchemaService.get_table_names()
        db_version = await SchemaService.get_db_version()
        
        current_db_key = SchemaService.get_current_db_key()
        database_name = "ä¸šåŠ¡æ•°æ®åº“"
        db_type = "mysql"
        
        if current_db_key in DATABASES:
            database_name = DATABASES[current_db_key]["name"]
            db_type = DATABASES[current_db_key].get("type", "mysql")
        
        if db_type == "mysql":
            database_type_info = "ã€æ•°æ®åº“ç±»å‹ã€‘\nMySQL"
            table_list_query = "è¯·ä½¿ç”¨ï¼šSHOW TABLES"
            quote_char = "`"
        elif db_type == "postgresql":
            database_type_info = "ã€æ•°æ®åº“ç±»å‹ã€‘\nPostgreSQL"
            table_list_query = "è¯·ä½¿ç”¨ï¼šSELECT tablename FROM pg_tables WHERE schemaname = 'public'"
            quote_char = '"'
        else:
            database_type_info = f"ã€æ•°æ®åº“ç±»å‹ã€‘\n{db_type}"
            table_list_query = "è¯·æ ¹æ®æ•°æ®åº“ç±»å‹ä½¿ç”¨æ ‡å‡† SQL æŸ¥è¯¢è¡¨åˆ—è¡¨"
            quote_char = '"'

        yield {"event": "thinking", "data": {"content": "æ­£åœ¨ç†è§£æ‚¨çš„é—®é¢˜..."}}
        yield {"event": "schema_loaded", "data": {"tables": tables}}

        intent = await self._classify_intent(question)

        if intent == "chat":
            full_summary_reasoning = ""
            summary_content = ""
            async for stream_event in self._generate_chat_response_stream(question, history_str, enable_thinking, database_name, db_type, ", ".join(tables)):
                if stream_event["type"] == "reasoning":
                    full_summary_reasoning += stream_event["content"]
                    yield {"event": "model_thinking", "data": {"content": stream_event["content"]}}
                elif stream_event["type"] == "content":
                    summary_content += stream_event["content"]
                    yield {"event": "summary", "data": {"content": stream_event["content"]}}
            yield {"event": "done", "data": {"summary": summary_content, "reasoning": full_summary_reasoning}}
            return

        # HITL é€»è¾‘
        is_executing_after_plan = (intent == "confirmation")
        if intent == "sql_query" and not is_executing_after_plan:
            plan_prompt = PLAN_GENERATION_PROMPT.format(database_name=database_name, database_type=db_type, schema=schema, history=history_str, question=question)
            full_plan = ""
            full_reasoning = ""
            async for delta in self._chat_completion_stream([{"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®åˆ†æé¡¾é—®ã€‚"}, {"role": "user", "content": plan_prompt}], temperature=0.3, enable_thinking=enable_thinking):
                if delta["reasoning_content"]:
                    full_reasoning += delta["reasoning_content"]
                    yield {"event": "model_thinking", "data": {"content": delta["reasoning_content"]}}
                if delta["content"]:
                    full_plan += delta["content"]
                    yield {"event": "summary", "data": {"content": delta["content"]}}
            yield {"event": "done", "data": {"summary": full_plan, "reasoning": full_reasoning}}
            return

        execution_question = question
        last_error = ""
        if is_executing_after_plan:
            execution_question = f"æ ¹æ®ä½ åˆšæ‰æå‡ºçš„åˆ†ææ–¹æ¡ˆï¼Œè¯·ç«‹å³ç”Ÿæˆæœ€ç»ˆçš„ SELECT SQL è¯­å¥å¹¶æ‰§è¡ŒæŸ¥è¯¢ã€‚ä¸¥ç¦ä½¿ç”¨ DROP/CREATE ç­‰æ“ä½œã€‚å½“å‰æŒ‡ä»¤ï¼š{question}"

        for attempt in range(MAX_RETRY_COUNT + 1):
            try:
                # å¦‚æœæ˜¯é‡è¯•ï¼Œå°†é”™è¯¯ä¿¡æ¯åŠ å…¥ä¸Šä¸‹æ–‡
                current_question = execution_question
                if last_error:
                    current_question = f"ä½ ä¸Šä¸€æ¬¡ç”Ÿæˆçš„ SQL æ‰§è¡Œå¤±è´¥äº†ï¼Œé”™è¯¯ä¿¡æ¯æ˜¯ï¼š{last_error}ã€‚è¯·ä¿®æ­£ SQL å¹¶é‡æ–°ç”Ÿæˆã€‚åªå…è®¸ SELECT è¯­å¥ã€‚åŸå§‹æŒ‡ä»¤ï¼š{execution_question}"

                full_reasoning = ""
                sql_response = None
                async for stream_event in self.generate_sql_stream(current_question, schema, history_str, enable_thinking, database_name, database_type_info, db_version, table_list_query, quote_char):
                    if stream_event["type"] == "reasoning":
                        full_reasoning += stream_event["content"]
                        yield {"event": "model_thinking", "data": {"content": stream_event["content"]}}
                    elif stream_event["type"] == "done":
                        sql_response = stream_event["result"]
                
                if not sql_response: raise ValueError("æœªèƒ½ç”Ÿæˆæœ‰æ•ˆçš„ SQL JSON å“åº”")
                
                sql = sql_response.get("sql", "")
                if not sql: raise ValueError("ç”Ÿæˆçš„ JSON ä¸­æ²¡æœ‰ SQL è¯­å¥")
                
                chart_type = sql_response.get("chart_type", "table")
                viz_config = sql_response.get("viz_config", {})

                yield {"event": "sql_generated", "data": {"sql": sql}}
                yield {"event": "sql_executing", "data": {"content": "æ­£åœ¨æŸ¥è¯¢æ•°æ®åº“..."}}

                sql_result = await SQLExecutor.execute_sql(sql)
                yield {"event": "sql_result", "data": sql_result}
                
                # å…³é”®ï¼šä¼ é€’ viz_config
                chart_config = await self.generate_chart_config(sql_result, chart_type, viz_config)
                yield {"event": "chart_ready", "data": {"option": chart_config, "chart_type": chart_config.get("chart_type", chart_type)}}
                
                formatted_result = SQLExecutor.format_sql_result(sql_result)
                summary = ""
                async for stream_event in self.generate_summary_stream(formatted_result, chart_type, enable_thinking):
                    if stream_event["type"] == "reasoning":
                        yield {"event": "model_thinking", "data": {"content": stream_event["content"]}}
                    elif stream_event["type"] == "content":
                        summary += stream_event["content"]
                        yield {"event": "summary", "data": {"content": stream_event["content"]}}
                
                yield {"event": "done", "data": {"sql": sql, "chart_config": chart_config, "summary": summary, "reasoning": full_reasoning, "session_title": sql_response.get("session_title", "")}}
                break

            except Exception as e:
                last_error = str(e)
                print(f"âŒ [Agent] SQL æ‰§è¡Œå°è¯• {attempt + 1} å¤±è´¥: {last_error}")
                if attempt >= MAX_RETRY_COUNT:
                    yield {"event": "error", "data": {"message": f"åˆ†æå¤±è´¥: {last_error}"}}
                    return
